Okay, so we've just made changes to add some heuristic information to the Q-Learnign Algorithm.
Namely, what we've changed is the canSee method, and the choseActions in the Predators and Preys.

In the process of doing this, we've broken something, and now the dots are not moving.

---

Here's our code:

//agent.js

const bresenhamLine = require('../helpers/bresenhamLine');

class Agent {
  constructor(x, y, grid) {
    this.grid = grid;
    if (x !== undefined && y !== undefined) {
      this.setPosition(x, y);
    }
    this.qTable = {};
    this.stepCount = 0;
    this.fieldOfView = this.fieldOfView || 360;
  }

  setPosition(x, y) {
    const newX = x % this.grid.size;
    const newY = y % this.grid.size;

    if (this.grid.isValidMove(newX, newY)) {
      this.x = newX;
      this.y = newY;
    } else {
      // Find the nearest valid position
      const validPositions = this.getValidNeighborPositions();
      if (validPositions.length > 0) {
        const nearestValidPosition = validPositions.reduce((prev, curr) => {
          const prevDistance = this.calculateDistance(x, y, prev.x, prev.y);
          const currDistance = this.calculateDistance(x, y, curr.x, curr.y);
          return prevDistance < currDistance ? prev : curr;
        });

        this.x = nearestValidPosition.x;
        this.y = nearestValidPosition.y;
      } else {
        throw new Error('Invalid move', x, y);
      }
    }
  }

  getValidNeighborPositions() {
    const neighbors = [
      { x: (this.x - 1 + this.grid.size) % this.grid.size, y: this.y },
      { x: (this.x + 1) % this.grid.size, y: this.y },
      { x: this.x, y: (this.y - 1 + this.grid.size) % this.grid.size },
      { x: this.x, y: (this.y + 1) % this.grid.size },
      {
        x: (this.x - 1 + this.grid.size) % this.grid.size,
        y: (this.y - 1 + this.grid.size) % this.grid.size,
      },
      {
        x: (this.x + 1) % this.grid.size,
        y: (this.y - 1 + this.grid.size) % this.grid.size,
      },
      {
        x: (this.x - 1 + this.grid.size) % this.grid.size,
        y: (this.y + 1) % this.grid.size,
      },
      { x: (this.x + 1) % this.grid.size, y: (this.y + 1) % this.grid.size },
    ];

    return neighbors.filter((neighbor) =>
      this.grid.isValidMove(neighbor.x, neighbor.y)
    );
  }

  getActions() {
    return [
      'up',
      'down',
      'left',
      'right',
      'up-left',
      'up-right',
      'down-left',
      'down-right',
    ];
  }

  calculateDistance(x1, y1, x2, y2) {
    const dx = Math.abs(x1 - x2);
    const dy = Math.abs(y1 - y2);
    const wrappedDx = Math.min(dx, this.grid.size - dx);
    const wrappedDy = Math.min(dy, this.grid.size - dy);
    return Math.sqrt(Math.pow(wrappedDx, 2) + Math.pow(wrappedDy, 2));
  }

  move(action) {
    let newX = this.x;
    let newY = this.y;

    switch (action) {
      case 'up':
        newY = (this.y - 1 + this.grid.size) % this.grid.size;
        break;
      case 'down':
        newY = (this.y + 1) % this.grid.size;
        break;
      case 'left':
        newX = (this.x - 1 + this.grid.size) % this.grid.size;
        break;
      case 'right':
        newX = (this.x + 1) % this.grid.size;
        break;
      case 'up-left':
        newX = (this.x - 1 + this.grid.size) % this.grid.size;
        newY = (this.y - 1 + this.grid.size) % this.grid.size;
        break;
      case 'up-right':
        newX = (this.x + 1) % this.grid.size;
        newY = (this.y - 1 + this.grid.size) % this.grid.size;
        break;
      case 'down-left':
        newX = (this.x - 1 + this.grid.size) % this.grid.size;
        newY = (this.y + 1) % this.grid.size;
        break;
      case 'down-right':
        newX = (this.x + 1) % this.grid.size;
        newY = (this.y + 1) % this.grid.size;
        break;
    }

    if (this.grid.isValidMove(newX, newY)) {
      this.x = newX;
      this.y = newY;
    }
  }

  canSee(otherAgent) {
    const distance = this.calculateDistance(
      this.x,
      this.y,
      otherAgent.x,
      otherAgent.y
    );

    // Calculate the angle between agent and otherAgent
    const angle =
      Math.atan2(otherAgent.y - this.y, otherAgent.x - this.x) *
      (180 / Math.PI);

    // Normalize the angle to be between 0 and 360
    const normalizedAngle = (angle + 360) % 360;

    // Check if normalizedAngle is within the field of view
    const halfFOV = this.fieldOfView / 2;
    const lowerBound = (normalizedAngle - halfFOV + 360) % 360;
    const upperBound = (normalizedAngle + halfFOV) % 360;

    const isWithinFOV =
      (lowerBound < upperBound &&
        normalizedAngle >= lowerBound &&
        normalizedAngle <= upperBound) ||
      (lowerBound > upperBound &&
        (normalizedAngle >= lowerBound || normalizedAngle <= upperBound));

    if (distance > this.visionRange || !isWithinFOV) {
      return false;
    }

    const linePoints = bresenhamLine(
      this.x,
      this.y,
      otherAgent.x,
      otherAgent.y
    );

    // Check if there's a direct line of sight without any obstacles
    return !linePoints.some((point) => this.grid.isObstacle(point.x, point.y));
  }

  getState() {
    return { x: this.x, y: this.y };
  }

  stateToString(state) {
    return `${state.x},${state.y}`;
  }

  chooseAction(state, temp) {
    const stateStr = this.stateToString(state);
    const actions = this.getActions();
    if (!this.qTable[stateStr]) {
      // Initialize the qTable for all possible actions with 0 values
      this.qTable[stateStr] = {};
      actions.forEach((action) => {
        this.qTable[stateStr][action] = 0;
      });
    }

    const defaultHeuristics = new Array(actions.length).fill(0);

    const actionProbabilities = this.calculateActionProbabilities(
      stateStr,
      actions,
      temp,
      defaultHeuristics
    );
    return this.selectActionBasedOnProbabilities(actions, actionProbabilities);
  }

  calculateActionProbabilities(stateStr, actions, temp, heuristics) {
    // Initialize the qTable for the state if not already initialized
    if (!this.qTable[stateStr]) {
      this.qTable[stateStr] = {};
      actions.forEach((action) => {
        this.qTable[stateStr][action] = 0;
      });
    }

    const maxQValue = Math.max(
      ...actions.map((action) => this.qTable[stateStr][action])
    );

    const rawProbabilities = actions.map((action, index) => {
      const qValue = this.qTable[stateStr][action] || 0;
      const heuristicValue = heuristics[index] || 0;
      return Math.exp((qValue + heuristicValue - maxQValue) / temp);
    });

    // Calculate the sum of raw probabilities
    const sumProbabilities = rawProbabilities.reduce((a, b) => a + b, 0);

    // Normalize the probabilities by dividing each probability by the sum of all probabilities
    const normalizedProbabilities = rawProbabilities.map((probability) => {
      return probability / sumProbabilities;
    });

    return normalizedProbabilities;
  }

  selectActionBasedOnProbabilities(actions, probabilities) {
    const sumProbabilities = probabilities.reduce((a, b) => a + b, 0);
    const randomValue = Math.random() * sumProbabilities;

    let cumulativeProb = 0;
    for (let i = 0; i < probabilities.length; i++) {
      cumulativeProb += probabilities[i];
      if (randomValue < cumulativeProb) {
        return actions[i];
      }
    }
  }

  updateQTable(state, action, reward, nextState) {
    const stateStr = this.stateToString(state);
    const nextStateStr = this.stateToString(nextState);
    if (!this.qTable[stateStr]) {
      this.qTable[stateStr] = {};
    }
    const oldQ = this.qTable[stateStr][action] || 0;
    const nextMaxQ = Math.max(
      ...Object.values(this.qTable[nextStateStr] || {})
    );
    const learningRate = 1 / (1 + this.stepCount / 1000);

    this.qTable[stateStr][action] =
      oldQ + learningRate * (reward + 0.9 * nextMaxQ - oldQ);
    this.stepCount++;
  }
}

module.exports = Agent;

---


//predator.js

const Agent = require('./agent');
class Predator extends Agent {
  constructor(x, y, grid, preys) {
    super(x, y, grid);
    this.fieldOfView = 90;
    this.qTable = {};
    this.history = [];
    this.preys = preys;
    this.visionRange = 5;
  }

  chooseAction(state) {
    const visiblePreys = this.preys.filter((prey) => this.canSee(prey));
    const visibleObstacles = this.grid.obstacles.filter((obstacle) =>
      this.canSee({ x: obstacle.x, y: obstacle.y })
    );

    const actions = this.getActions();

    // If no visible preys, choose a random action
    if (visiblePreys.length === 0) {
      const temp = Math.max(1.4 - this.stepCount / 10000, 0.1);
      return super.chooseAction(state, temp);
    }

    const closestPrey = visiblePreys.reduce((closest, current) => {
      const closestDistance = this.calculateDistance(
        this.x,
        this.y,
        closest.x,
        closest.y
      );
      const currentDistance = this.calculateDistance(
        this.x,
        this.y,
        current.x,
        current.y
      );
      return currentDistance < closestDistance ? current : closest;
    });

    // Calculate heuristic values for each action
    const heuristicValues = actions.map((action) => {
      const { x: newX, y: newY } = this.getNewPositionAfterAction(action);

      const distanceToPrey = this.calculateDistance(
        newX,
        newY,
        closestPrey.x,
        closestPrey.y
      );
      const distanceToClosestObstacle = Math.min(
        ...visibleObstacles.map((obstacle) =>
          this.calculateDistance(newX, newY, obstacle.x, obstacle.y)
        )
      );

      const preyHeuristicFactor = -1.5; // Adjust this value to change the prey heuristic scaling
      const obstacleHeuristicFactor = 0.5; // Adjust this value to change the obstacle heuristic scaling
      const minObstacleDistance = 1; // Adjust this value to set the minimum allowed distance to an obstacle

      const preyHeuristic = preyHeuristicFactor * distanceToPrey;
      const obstacleHeuristic =
        distanceToClosestObstacle < minObstacleDistance
          ? obstacleHeuristicFactor * distanceToClosestObstacle
          : 0;

      return preyHeuristic + obstacleHeuristic;
    });

    console.log(heuristicValues);

    const stateStr = this.stateToString(state);
    const temp = Math.max(1.4 - this.stepCount / 10000, 0.1);
    const actionProbabilities = this.calculateActionProbabilities(
      stateStr,
      actions,
      temp,
      heuristicValues
    );

    return this.selectActionBasedOnProbabilities(actions, actionProbabilities);
  }

  getNewPositionAfterAction(action) {
    let newX = this.x;
    let newY = this.y;

    switch (action) {
      case 'up':
        newY = (this.y - 1 + this.grid.size) % this.grid.size;
        break;
      case 'down':
        newY = (this.y + 1) % this.grid.size;
        break;
      case 'left':
        newX = (this.x - 1 + this.grid.size) % this.grid.size;
        break;
      case 'right':
        newX = (this.x + 1) % this.grid.size;
        break;
      case 'up-left':
        newX = (this.x - 1 + this.grid.size) % this.grid.size;
        newY = (this.y - 1 + this.grid.size) % this.grid.size;
        break;
      case 'up-right':
        newX = (this.x + 1) % this.grid.size;
        newY = (this.y - 1 + this.grid.size) % this.grid.size;
        break;
      case 'down-left':
        newX = (this.x - 1 + this.grid.size) % this.grid.size;
        newY = (this.y + 1) % this.grid.size;
        break;
      case 'down-right':
        newX = (this.x + 1) % this.grid.size;
        newY = (this.y + 1) % this.grid.size;
        break;
    }

    return { x: newX, y: newY };
  }

  // ...

  getReward(preyState, obstacleStates) {
    const dx = Math.abs(this.x - preyState.x);
    const dy = Math.abs(this.y - preyState.y);
    const wrappedDx = Math.min(dx, this.grid.size - dx);
    const wrappedDy = Math.min(dy, this.grid.size - dy);
    const distanceToPrey = Math.sqrt(
      Math.pow(wrappedDx, 2) + Math.pow(wrappedDy, 2)
    );

    // Calculate the distance to the closest obstacle
    const distanceToClosestObstacle = Math.min(
      ...obstacleStates.map((obstacle) =>
        this.calculateDistance(this.x, this.y, obstacle.x, obstacle.y)
      )
    );

    const rewardFactor = 1.5; // Adjust this value to change the reward scaling
    const obstaclePenaltyFactor = 0.5; // Adjust this value to change the obstacle penalty scaling
    const minObstacleDistance = 1; // Adjust this value to set the minimum allowed distance to an obstacle

    const preyReward = -Math.pow(distanceToPrey, rewardFactor);
    const obstaclePenalty =
      distanceToClosestObstacle < minObstacleDistance
        ? -Math.pow(distanceToClosestObstacle, obstaclePenaltyFactor)
        : 0;

    return preyReward + obstaclePenalty;
  }
}

module.exports = Predator;

---

//simulation.js

const Predator = require('../agents/predator');
const Prey = require('../agents/prey');
const Grid = require('../environment/grid');
const Monitoring = require('../monitoring/monitoring');
const config = require('./config');

const MAX_STEPS_PER_EPISODE = config.MAX_STEPS_PER_EPISODE;

// Create a new grid
const grid = new Grid(config.gridSize);
const monitoring = new Monitoring();

let predatorTotalReward = 0;
let preyTotalReward = 0;
let stepCount = 0;
let episodeCount = 0;

let collisionRewardPredator = config.collisionRewardPredator;
let collisionRewardPrey = config.collisionRewardPrey;

const nrOfObstacles = config.nrOfObstacles;

const predators = [];
const preys = [];

for (let i = 0; i < config.nrOfPredators; i++) {
  predators.push(new Predator(null, null, grid, preys));
  preys.push(new Prey(null, null, grid, predators));
}

// Rely on placePredators and placePreys methods to set positions
grid.setPredatorsAndPreys(predators, preys);
grid.placePredators(predators);
grid.placePreys(preys);

//Knuth algortihm, ensuring that each permutation of the array elements has an equal probability of appearance.
//Not needed currently, but might be useful in the future

// function shuffleArray(array) {
//   for (let i = array.length - 1; i > 0; i--) {
//     const j = Math.floor(Math.random() * (i + 1));
//     [array[i], array[j]] = [array[j], array[i]];
//   }
// }

function resetPositions() {
  monitoring.logEpisodeResults(predatorTotalReward, preyTotalReward, stepCount);
  // monitoring.logQValues(testingPredator.qTable);
  predatorTotalReward = 0;
  preyTotalReward = 0;
  stepCount = 0;

  grid.placePredators(predators);
  grid.placePreys(preys);
}

for (let i = 0; i < nrOfObstacles; i++) {
  let obstaclePos = grid.randomPosition();
  while (
    predators.some((p) => p.x === obstaclePos.x && p.y === obstaclePos.y) ||
    preys.some((p) => p.x === obstaclePos.x && p.y === obstaclePos.y)
  ) {
    obstaclePos = grid.randomPosition();
  }
  grid.addObstacle(obstaclePos.x, obstaclePos.y);
}

function runStep(predator, prey) {
  const predatorAction = predator.chooseAction(predator.getState());
  predator.move(predatorAction);

  const preyAction = prey.chooseAction(prey.getState());
  prey.move(preyAction);

  const predatorVisibleObstacles = grid.obstacles.filter((obstacle) => {
    predator.canSee({ x: obstacle.x, y: obstacle.y });
  });

  const predatorReward = predator.getReward(
    prey.getState(),
    predatorVisibleObstacles
  );

  const preyVisibleObstacles = grid.obstacles.filter((obstacle) => {
    prey.canSee({ x: obstacle.x, y: obstacle.y });
  });

  const preyReward = prey.getReward(predator.getState(), preyVisibleObstacles);

  if (predator.canSee(prey)) {
    console.log(
      `Predator at (${predator.x}, ${predator.y}) can see prey at (${prey.x}, ${prey.y})`
    );
  }

  if (prey.canSee(predator)) {
    console.log(
      `Prey at (${prey.x}, ${prey.y}) can see prey at (${predator.x}, ${predator.y})`
    );
  }

  if (predator.canSee(prey)) {
    console.log(
      `Predator at (${predator.x}, ${predator.y}) can see prey at (${prey.x}, ${prey.y})`
    );
  }

  // do {
  //   console.log(
  //     `Prey at (${prey.x}, ${prey.y}) can see predator at (${predator.x}, ${predator.y})`
  //   );
  // } while (prey.canSee(predator));

  const isCaught = grid.isCollision(predator.x, predator.y, prey.x, prey.y);

  if (isCaught || stepCount >= MAX_STEPS_PER_EPISODE) {
    episodeCount++;

    predatorTotalReward += predatorReward;
    preyTotalReward += preyReward;

    if (isCaught) {
      predatorTotalReward += collisionRewardPredator;
      preyTotalReward += collisionRewardPrey;
    }

    resetPositions();
  } else {
    predatorTotalReward += predatorReward;
    preyTotalReward += preyReward;
  }

  predator.updateQTable(
    predator.getState(),
    predatorAction,
    predatorReward,
    predator.getState()
  );
  prey.updateQTable(prey.getState(), preyAction, preyReward, prey.getState());
}

async function startSimulation(io, socket) {
  socket.emit('data', {
    predators: predators.map(({ x, y }) => ({ x, y })),
    preys: preys.map(({ x, y }) => ({ x, y })),
    obstacles: grid.obstacles,
    monitoring: {
      episodeResults: monitoring.episodeResults,
      qValues: monitoring.qValues,
    },
  });

  while (true) {
    predators.forEach((predator) => {
      preys.forEach((prey) => {
        runStep(predator, prey);
      });
    });

    stepCount++;

    socket.emit('data', {
      predators: predators.map(({ x, y }) => ({ x, y })),
      preys: preys.map(({ x, y }) => ({ x, y })),
      obstacles: grid.obstacles,
      monitoring: {
        episodeResults: monitoring.episodeResults,
        qValues: monitoring.qValues,
      },
    });

    // Wait for 2000 milliseconds before running the next iteration
    await new Promise((resolve) => setTimeout(resolve, 2000));
  }
}

module.exports = { startSimulation };

---

//public/script.js

const socket = io();
const gridEl = document.getElementById('grid');

const agentSize = 10;

const updateInterval = 10; // Update the plots every 10 data points
let dataPointsReceived = 0;
let config;

socket.on('data', (data) => {
  updateDots(data.obstacles, 'obstacle');
  updateDots(data.predators, 'predator', data.visiblePreysForPredators);
  updateDots(data.preys, 'prey', data.visiblePredatorsForPreys);
});

function updateDots(agentData, type, visibilityData) {
  const existingDots = document.querySelectorAll(`.${type}`);

  // Remove extra dots if there are more on the DOM than in the new data
  for (let i = agentData.length; i < existingDots.length; i++) {
    existingDots[i].remove();
  }

  agentData.forEach((agent, index) => {
    let dotElement;

    if (index < existingDots.length) {
      // Update the position of an existing dot
      dotElement = existingDots[index];
      moveDot(dotElement, agent.x, agent.y);
    } else {
      // Create a new dot if there are fewer on the DOM than in the new data
      dotElement = createDot(agent.x, agent.y, type);
    }

    if (visibilityData) {
      dotElement.style.opacity = visibilityData[index] ? 1 : 0.3;
    } else {
      dotElement.style.opacity = 1;
    }
  });
}

function createDot(x, y, type) {
  const dotElement = document.createElement('div');
  dotElement.id = `${type}-${Date.now()}`;
  dotElement.className = type;

  dotElement.style.width = `${agentSize}px`;
  dotElement.style.height = `${agentSize}px`;
  dotElement.style.borderRadius = '100%';
  dotElement.style.position = 'absolute';

  gridEl.appendChild(dotElement);

  if (type !== 'obstacle') {
    moveDot(dotElement, x, y);
  } else {
    dotElement.style.borderRadius = '20%';
    // Set obstacle position without animation
    moveDot(dotElement, x, y, false);
  }

  const cellSize =
    Math.min(window.innerWidth, window.innerHeight) / config.gridSize;
  dotElement.style.transform = `translate(${x * cellSize}px, ${
    y * cellSize
  }px)`;

  return dotElement;
}

function moveDot(dot, x, y, animate = true) {
  const cellSize =
    Math.min(window.innerWidth, window.innerHeight) / config.gridSize;

  if (animate) {
    gsap.to(dot, {
      duration: 2, // Animation duration
      x: x * cellSize, // Compute X position
      y: y * cellSize, // Compute Y position
      ease: 'sine.inOut', // Animation easing function
    });
  } else {
    dot.style.transform = `translate(${x * cellSize}px, ${y * cellSize}px)`;
  }
}

function generateEmptyCells() {
  // Clear the grid
  gridEl.innerHTML = '';

  // Generate new cells based on the gridSize from the config
  for (let i = 0; i < config.gridSize * config.gridSize; i++) {
    const gridCell = document.createElement('div');
    gridCell.className = 'grid-cell';
    gridEl.appendChild(gridCell);
  }

  // Update the grid template columns and rows
  gridEl.style.gridTemplateColumns = `repeat(${config.gridSize}, 1fr)`;
  gridEl.style.gridTemplateRows = `repeat(${config.gridSize}, 1fr)`;
}

fetch('/config')
  .then((response) => response.json())
  .then((data) => {
    config = data;
    generateEmptyCells();
  });

---

<!-- public/index.html -->

<!DOCTYPE html>
<html>
  <head>
    <title>Predator-Prey Simulation</title>
    <script src="/socket.io/socket.io.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.9.1/gsap.min.js"></script>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

    <style>
      body,
      html {
        margin: 0;
        padding: 0;
        height: 100%;
        width: 100%;
        overflow: hidden;
        display: flex;
        flex-direction: column;
      }
      #container {
        display: grid;
        grid-template-columns: repeat(2, 1fr);
        gap: 20px;
        padding: 20px;
        bottom: 0;
      }

      #grid {
        position: absolute;
        top: 0;
        left: 0;
        display: grid;
        gap: 1px;
        width: 100vw;
        height: 100vh;
        border: 1px solid black;
        box-sizing: border-box;
        min-height: calc(
          100% - 320px
        ); /* 320px = plot height + bottom margin */
      }

      .obstacle {
        background-color: gray;
      }

      .predator {
        background-color: red;
      }
      .prey {
        background-color: blue;
      }
      .grid-cell {
        background-color: white;
      }
    </style>
  </head>
  <body>
    <div id="grid">
      <!-- Empty cells to create grid structure -->
    </div>

    <script src="script.js"></script>
  </body>
</html>

