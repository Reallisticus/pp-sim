This is a Predator/Prey AI Simulation using Reinforcement Learning (Q-Learning Algorithm) in a 2D grid environment. The simulation consists of predators and preys, each represented by their respective classes, Predator and Prey, which are both subclasses of the Agent class. The Grid class represents the environment.

Here's a high-level overview of how the simulation works:

1. The Agent class provides basic functionality for both predators and preys, such as moving, getting the current state, and updating the Q-Table.

2. The Predator and Prey classes inherit from the Agent class and implement their own chooseAction method to decide which action to take based on their Q-Table. They also have their own getReward method to calculate the reward based on the distance between predator and prey.

3. The Grid class represents the environment and provides methods for placing predators and preys randomly on the grid, checking for collisions, and validating moves.

4. The simulation.js file sets up the grid, creates instances of predators and preys, and runs the simulation in a loop. In each step of the loop, predators and preys choose actions, move, update their Q-Tables, and calculate rewards. If a predator catches a prey or the maximum number of steps per episode is reached, the positions of predators and preys are reset, and a new episode begins.

5. The script.js file handles the visualization of the simulation in the browser using socket.io to receive data from the server and GSAP for animations.

6. The index.html file sets up the structure of the web page and includes necessary styles for displaying the grid, predators, and preys.
